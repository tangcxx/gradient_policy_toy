{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424fc8e6-e309-4608-b270-a4fd7161eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from itertools import product\n",
    "\n",
    "def make_state():\n",
    "    state = np.zeros(8)\n",
    "    state[np.random.choice(8, size=3, replace=False)] = np.random.uniform(size=3)\n",
    "    return state\n",
    "\n",
    "def run(state, action):\n",
    "    state_cyclic = np.concatenate((state, state[0:2]))\n",
    "    if state_cyclic[action] != 0:\n",
    "        return state_cyclic[action]\n",
    "    elif state_cyclic[action-1] != 0 and state_cyclic[action+1] != 0:\n",
    "        return state_cyclic[action-1] + state_cyclic[action+1]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_optimal_value(state):\n",
    "    value = state.max()\n",
    "\n",
    "    state_cyclic = np.concatenate((state, state[0:2]))\n",
    "    for i in np.arange(1, 9):\n",
    "        if state_cyclic[i] == 0 and state_cyclic[i-1] != 0 and state_cyclic[i+1] != 0:\n",
    "            value2 = state_cyclic[i-1] + state_cyclic[i+1]\n",
    "            if value2 > value:\n",
    "                value = value2\n",
    "    return value\n",
    "\n",
    "def get_optimal_statics(n_rounds):\n",
    "    values = np.array([get_optimal_value(make_state()) for i in np.arange(n_rounds)])\n",
    "    return np.mean(values), np.std(values)\n",
    "\n",
    "def get_baseline_value(n_rounds):\n",
    "    values = [run(make_state(), np.random.choice(8)) for i in np.arange(n_rounds)]\n",
    "    return np.mean(values)\n",
    "    \n",
    "\n",
    "def get_optimal_action(state):\n",
    "    action = state.argmax()\n",
    "    value = state[action]\n",
    "    state_cyclic = np.concatenate((state, state[0:2]))\n",
    "    for i in np.arange(1, 9):\n",
    "        if state_cyclic[i] == 0 and state_cyclic[i-1] != 0 and state_cyclic[i+1] != 0:\n",
    "            value2 = state_cyclic[i-1] + state_cyclic[i+1]\n",
    "            if value2 > value:\n",
    "                value = value2\n",
    "                action = i % 8\n",
    "    return action\n",
    "\n",
    "def get_optimal_actions(state_list):\n",
    "    return np.array([get_optimal_action(state) for state in state_list])\n",
    "    \n",
    "\n",
    "def get_model_actions(model, state_list):\n",
    "    return model(np.array(state_list)).numpy().argmax(axis = 1)\n",
    "\n",
    "def test_model(model, n_test_rounds):\n",
    "    state_list = np.array([make_state() for i in np.arange(n_test_rounds)])\n",
    "    actions = get_model_actions(model, state_list)\n",
    "    values = [run(state, action) for state, action in zip(state_list, actions)]\n",
    "    return np.mean(values)\n",
    "\n",
    "def test_model_accuracy(model, n_test_rounds):\n",
    "    count = 0\n",
    "    state_list = [make_state() for i in np.arange(n_test_rounds)]\n",
    "    optimal_values = np.array([get_optimal_value(state) for state in state_list])\n",
    "    model_actions = get_model_actions(model, state_list)\n",
    "    model_values = np.array([run(state, action) for state, action in zip(state_list, model_actions)])\n",
    "    return np.sum(np.abs(optimal_values - model_values) < 1e-6)/n_test_rounds\n",
    "\n",
    "def one_batch_supervised(model, batch_size, n_test_rounds=0):\n",
    "    state_list = []\n",
    "    y_target_list = []\n",
    "    # rewards = 0\n",
    "    for i in np.arange(batch_size):\n",
    "        state = make_state()\n",
    "        action = get_optimal_action(state)\n",
    "        y_target = np.zeros(8)\n",
    "        y_target[action] = 1\n",
    "        state_list.append(state)\n",
    "        y_target_list.append(y_target)\n",
    "    model.fit(np.array(state_list), np.array(y_target_list), verbose=0)\n",
    "    if n_test_rounds > 0:\n",
    "        return (test_model(model, n_test_rounds))\n",
    "\n",
    "def train(model, max_batch=200, batch_size=128, n_test_rounds=10000, verbose = 0):\n",
    "    best_weights = []\n",
    "    best_idx = 0\n",
    "    best_score = 0\n",
    "    for i in np.arange(max_batch):\n",
    "        score = one_batch(model, batch_size, n_test_rounds)\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_idx = i\n",
    "            best_weights = model.get_weights()\n",
    "        if verbose == 1:\n",
    "            print(i, score)\n",
    "    return best_idx, best_score, best_weights\n",
    "\n",
    "def train_supervised(model, max_batch=200, batch_size=128, n_test_rounds=10000, verbose = 0):\n",
    "    best_weights = []\n",
    "    best_idx = 0\n",
    "    best_score = 0\n",
    "    for i in np.arange(max_batch):\n",
    "        score = one_batch_supervised(model, batch_size, n_test_rounds)\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_idx = i\n",
    "            best_weights = model.get_weights()\n",
    "        if verbose == 1:\n",
    "            print(i, score)\n",
    "    return best_idx, best_score, best_weights\n",
    "\n",
    "\n",
    "def create_model(n_hidden_layers, n_dense_units, ratio_dropout, optimizer):\n",
    "    input_shape = (8,) \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in np.arange(n_hidden_layers):\n",
    "        x = Dense(n_dense_units)(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Dropout(ratio_dropout)(x)\n",
    "    \n",
    "    outputs = Dense(8, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b7deff-a8fd-4e28-af79-bb0ef4ea6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(model, batch_size, n_test_rounds=0):\n",
    "    y_target_list = np.zeros((batch_size, 8))\n",
    "    state_list = np.array([make_state() for i in np.arange(batch_size)])\n",
    "    prob_list = model(np.array(state_list)).numpy()\n",
    "    actions = [np.random.choice(8, p=prob) for prob in prob_list]\n",
    "    values = [run(state, action) for state, action in zip(state_list, actions)]\n",
    "    for i in np.arange(batch_size):\n",
    "        y_target_list[i, actions[i]] = values[i]\n",
    "    model.fit(state_list, np.array(y_target_list), verbose = 0)\n",
    "    if n_test_rounds > 0:\n",
    "        return (test_model_accuracy(model, n_test_rounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c9f5b-7978-424a-9306-830646861770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614c09b5-893d-48c9-b83c-a32b805aeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_hidden_layers=1, n_dense_units=512, ratio_dropout=0.5, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8c1535-0e4a-4225-8581-87c3137a7560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1652\n",
      "1 0.2143\n",
      "2 0.223\n",
      "3 0.2157\n",
      "4 0.2402\n",
      "5 0.2746\n",
      "6 0.3085\n",
      "7 0.3169\n",
      "8 0.3381\n",
      "9 0.3438\n",
      "10 0.3408\n",
      "11 0.3464\n",
      "12 0.3635\n",
      "13 0.3868\n",
      "14 0.4065\n",
      "15 0.4025\n",
      "16 0.3745\n",
      "17 0.3723\n",
      "18 0.3882\n",
      "19 0.403\n",
      "20 0.4046\n",
      "21 0.3977\n",
      "22 0.3824\n",
      "23 0.3528\n",
      "24 0.317\n",
      "25 0.3209\n",
      "26 0.342\n",
      "27 0.3669\n",
      "28 0.4271\n",
      "29 0.4453\n",
      "30 0.4491\n",
      "31 0.4037\n",
      "32 0.3706\n",
      "33 0.3605\n",
      "34 0.3501\n",
      "35 0.3539\n",
      "36 0.389\n",
      "37 0.4079\n",
      "38 0.4259\n",
      "39 0.4309\n",
      "40 0.4197\n",
      "41 0.4338\n",
      "42 0.4496\n",
      "43 0.4316\n",
      "44 0.4388\n",
      "45 0.4378\n",
      "46 0.4125\n",
      "47 0.3917\n",
      "48 0.4029\n",
      "49 0.3969\n",
      "50 0.4181\n",
      "51 0.4133\n",
      "52 0.4125\n",
      "53 0.4075\n",
      "54 0.4033\n",
      "55 0.3947\n",
      "56 0.4073\n",
      "57 0.4254\n",
      "58 0.4429\n",
      "59 0.4124\n",
      "60 0.4065\n",
      "61 0.4092\n",
      "62 0.4055\n",
      "63 0.4175\n",
      "64 0.4402\n",
      "65 0.4521\n",
      "66 0.4658\n",
      "67 0.465\n",
      "68 0.4595\n",
      "69 0.4033\n",
      "70 0.4153\n",
      "71 0.4219\n",
      "72 0.4352\n",
      "73 0.4471\n",
      "74 0.4578\n",
      "75 0.4246\n",
      "76 0.436\n",
      "77 0.4391\n",
      "78 0.4195\n",
      "79 0.4195\n",
      "80 0.4221\n",
      "81 0.4293\n",
      "82 0.4269\n",
      "83 0.4093\n",
      "84 0.4138\n",
      "85 0.4173\n",
      "86 0.419\n",
      "87 0.4285\n",
      "88 0.4395\n",
      "89 0.425\n",
      "90 0.4291\n",
      "91 0.4281\n",
      "92 0.4279\n",
      "93 0.4387\n",
      "94 0.4288\n",
      "95 0.447\n",
      "96 0.4665\n",
      "97 0.4779\n",
      "98 0.4744\n",
      "99 0.4834\n",
      "100 0.5046\n",
      "101 0.5119\n",
      "102 0.4771\n",
      "103 0.4606\n",
      "104 0.4851\n",
      "105 0.47\n",
      "106 0.4572\n",
      "107 0.4884\n",
      "108 0.4748\n",
      "109 0.4592\n",
      "110 0.4487\n",
      "111 0.4143\n",
      "112 0.4091\n",
      "113 0.415\n",
      "114 0.4174\n",
      "115 0.436\n",
      "116 0.4553\n",
      "117 0.4337\n",
      "118 0.4122\n",
      "119 0.4005\n",
      "120 0.4111\n",
      "121 0.422\n",
      "122 0.4488\n",
      "123 0.4477\n",
      "124 0.4373\n",
      "125 0.4306\n",
      "126 0.4266\n",
      "127 0.4146\n",
      "128 0.4355\n",
      "129 0.4683\n",
      "130 0.4773\n",
      "131 0.4504\n",
      "132 0.4398\n",
      "133 0.451\n",
      "134 0.4504\n",
      "135 0.4556\n",
      "136 0.4533\n",
      "137 0.4712\n",
      "138 0.4758\n",
      "139 0.4577\n",
      "140 0.4544\n",
      "141 0.4669\n",
      "142 0.4828\n",
      "143 0.5081\n",
      "144 0.5022\n",
      "145 0.4976\n",
      "146 0.4985\n",
      "147 0.4881\n",
      "148 0.4807\n",
      "149 0.4634\n",
      "150 0.4643\n",
      "151 0.4682\n",
      "152 0.4362\n",
      "153 0.4169\n",
      "154 0.419\n",
      "155 0.3983\n",
      "156 0.4147\n",
      "157 0.4066\n",
      "158 0.4288\n",
      "159 0.463\n",
      "160 0.4638\n",
      "161 0.4578\n",
      "162 0.4414\n",
      "163 0.4013\n",
      "164 0.37\n",
      "165 0.3793\n",
      "166 0.3621\n",
      "167 0.3608\n",
      "168 0.4059\n",
      "169 0.4178\n",
      "170 0.44\n",
      "171 0.4548\n",
      "172 0.4449\n",
      "173 0.4254\n",
      "174 0.4187\n",
      "175 0.4387\n",
      "176 0.4279\n",
      "177 0.4137\n",
      "178 0.3941\n",
      "179 0.3563\n",
      "180 0.362\n",
      "181 0.3892\n",
      "182 0.3991\n",
      "183 0.3984\n",
      "184 0.3981\n",
      "185 0.3806\n",
      "186 0.388\n",
      "187 0.4019\n",
      "188 0.3784\n",
      "189 0.3771\n",
      "190 0.3819\n",
      "191 0.3776\n",
      "192 0.3723\n",
      "193 0.3875\n",
      "194 0.4\n",
      "195 0.3889\n",
      "196 0.3787\n",
      "197 0.4193\n",
      "198 0.4246\n",
      "199 0.3991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.int64(101), np.float64(0.8550526694847563), np.float64(0.4984))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx, best_score, best_weights = train(model, 200, verbose = 1)\n",
    "best_model = clone_model(model)\n",
    "best_model.set_weights(best_weights)\n",
    "best_idx, test_model(best_model, 10000), test_model_accuracy(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1757a199-9258-4f63-95c6-bfe5dca23520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(101), np.float64(0.8505431153828918), np.float64(0.5049))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx, test_model(best_model, 10000), test_model_accuracy(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6e3fe0-c5f1-4880-86e8-d4db3093a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7954792072723128), np.float64(0.4016))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, 10000), test_model_accuracy(model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d3dcf-e3a9-4d71-b5e3-b6187c8bc5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd3d8628-3b71-4b04-8509-a220df04bf45",
   "metadata": {},
   "source": [
    "## 仅按输赢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ee0b4c-e999-47dc-8019-ea17cd02b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(model, batch_size, n_test_rounds=0):\n",
    "    y_target_list = np.zeros((batch_size, 8))\n",
    "    state_list = np.array([make_state() for i in np.arange(batch_size)])\n",
    "    prob_list = model(np.array(state_list)).numpy()\n",
    "    actions = [np.random.choice(8, p=prob) for prob in prob_list]\n",
    "    optimal_actions = get_optimal_actions(state_list)\n",
    "    values = np.ones(batch_size)\n",
    "    values[actions != optimal_actions] = -1\n",
    "    for i in np.arange(batch_size):\n",
    "        y_target_list[i, actions[i]] = values[i]\n",
    "    model.fit(state_list, np.array(y_target_list), verbose = 0)\n",
    "    if n_test_rounds > 0:\n",
    "        return (test_model_accuracy(model, n_test_rounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180eb2a-2b7a-4e20-a102-ad59733d0974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627e57f2-8bb7-47bb-b98d-6fe78ad7327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_hidden_layers=1, n_dense_units=512, ratio_dropout=0.5, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fec043-f90c-4b13-8062-bc00afe2f6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1772\n",
      "1 0.1847\n",
      "2 0.1847\n",
      "3 0.1983\n",
      "4 0.2144\n",
      "5 0.2329\n",
      "6 0.2582\n",
      "7 0.2892\n",
      "8 0.2844\n",
      "9 0.3105\n",
      "10 0.3266\n",
      "11 0.3245\n",
      "12 0.3209\n",
      "13 0.3071\n",
      "14 0.288\n",
      "15 0.2805\n",
      "16 0.2908\n",
      "17 0.2798\n",
      "18 0.2909\n",
      "19 0.3148\n",
      "20 0.3293\n",
      "21 0.3339\n",
      "22 0.3595\n",
      "23 0.3661\n",
      "24 0.3584\n",
      "25 0.3628\n",
      "26 0.3795\n",
      "27 0.372\n",
      "28 0.3474\n",
      "29 0.3199\n",
      "30 0.3179\n",
      "31 0.3294\n",
      "32 0.3322\n",
      "33 0.3592\n",
      "34 0.3759\n",
      "35 0.3922\n",
      "36 0.3917\n",
      "37 0.3856\n",
      "38 0.3974\n",
      "39 0.4162\n",
      "40 0.4461\n",
      "41 0.4688\n",
      "42 0.4677\n",
      "43 0.4449\n",
      "44 0.3986\n",
      "45 0.3572\n",
      "46 0.3201\n",
      "47 0.3578\n",
      "48 0.4207\n",
      "49 0.4549\n",
      "50 0.4919\n",
      "51 0.4724\n",
      "52 0.427\n",
      "53 0.4414\n",
      "54 0.4539\n",
      "55 0.4509\n",
      "56 0.4825\n",
      "57 0.491\n",
      "58 0.4928\n",
      "59 0.4772\n",
      "60 0.4842\n",
      "61 0.4956\n",
      "62 0.4866\n",
      "63 0.4532\n",
      "64 0.4705\n",
      "65 0.4926\n",
      "66 0.5137\n",
      "67 0.5102\n",
      "68 0.5167\n",
      "69 0.522\n",
      "70 0.5215\n",
      "71 0.5157\n",
      "72 0.4895\n",
      "73 0.4755\n",
      "74 0.4573\n",
      "75 0.461\n",
      "76 0.5024\n",
      "77 0.4963\n",
      "78 0.4919\n",
      "79 0.5176\n",
      "80 0.4885\n",
      "81 0.473\n",
      "82 0.4343\n",
      "83 0.4375\n",
      "84 0.483\n",
      "85 0.4781\n",
      "86 0.5026\n",
      "87 0.5372\n",
      "88 0.5416\n",
      "89 0.5474\n",
      "90 0.5371\n",
      "91 0.4989\n",
      "92 0.4775\n",
      "93 0.5264\n",
      "94 0.5241\n",
      "95 0.5088\n",
      "96 0.5153\n",
      "97 0.4982\n",
      "98 0.4965\n",
      "99 0.5013\n",
      "100 0.4976\n",
      "101 0.4862\n",
      "102 0.4766\n",
      "103 0.4921\n",
      "104 0.5143\n",
      "105 0.5475\n",
      "106 0.503\n",
      "107 0.506\n",
      "108 0.5073\n",
      "109 0.4554\n",
      "110 0.4369\n",
      "111 0.5058\n",
      "112 0.5352\n",
      "113 0.5354\n",
      "114 0.5237\n",
      "115 0.5033\n",
      "116 0.5353\n",
      "117 0.5173\n",
      "118 0.5053\n",
      "119 0.543\n",
      "120 0.5144\n",
      "121 0.51\n",
      "122 0.5321\n",
      "123 0.5253\n",
      "124 0.5029\n",
      "125 0.4947\n",
      "126 0.4975\n",
      "127 0.4504\n",
      "128 0.5125\n",
      "129 0.5455\n",
      "130 0.574\n",
      "131 0.5437\n",
      "132 0.5131\n",
      "133 0.4985\n",
      "134 0.4476\n",
      "135 0.4782\n",
      "136 0.4937\n",
      "137 0.5027\n",
      "138 0.5092\n",
      "139 0.5269\n",
      "140 0.502\n",
      "141 0.4981\n",
      "142 0.5169\n",
      "143 0.5246\n",
      "144 0.5184\n",
      "145 0.5142\n",
      "146 0.5163\n",
      "147 0.4979\n",
      "148 0.4854\n",
      "149 0.4663\n",
      "150 0.4726\n",
      "151 0.4876\n",
      "152 0.5028\n",
      "153 0.5155\n",
      "154 0.5289\n",
      "155 0.4914\n",
      "156 0.4685\n",
      "157 0.4933\n",
      "158 0.4985\n",
      "159 0.4853\n",
      "160 0.5011\n",
      "161 0.5273\n",
      "162 0.4763\n",
      "163 0.4801\n",
      "164 0.489\n",
      "165 0.4757\n",
      "166 0.4777\n",
      "167 0.4817\n",
      "168 0.5172\n",
      "169 0.4903\n",
      "170 0.462\n",
      "171 0.5393\n",
      "172 0.5249\n",
      "173 0.5247\n",
      "174 0.5229\n",
      "175 0.4848\n",
      "176 0.4854\n",
      "177 0.515\n",
      "178 0.5228\n",
      "179 0.5081\n",
      "180 0.5036\n",
      "181 0.505\n",
      "182 0.5229\n",
      "183 0.5314\n",
      "184 0.4937\n",
      "185 0.5192\n",
      "186 0.4995\n",
      "187 0.5108\n",
      "188 0.4959\n",
      "189 0.4899\n",
      "190 0.4893\n",
      "191 0.4557\n",
      "192 0.4695\n",
      "193 0.4879\n",
      "194 0.5161\n",
      "195 0.4932\n",
      "196 0.4749\n",
      "197 0.4564\n",
      "198 0.4979\n",
      "199 0.5279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.int64(130), np.float64(0.7895633281217262), np.float64(0.5721))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx, best_score, best_weights = train(model, 200, verbose = 1)\n",
    "best_model = clone_model(model)\n",
    "best_model.set_weights(best_weights)\n",
    "best_idx, test_model(best_model, 10000), test_model_accuracy(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18efe877-a8d5-47cc-8968-2943e0f1451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(130), np.float64(0.7821927187467178), np.float64(0.566))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx, test_model(best_model, 10000), test_model_accuracy(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5982bb1a-cad1-4639-8558-4941192c079e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7928495540050106), np.float64(0.5247))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, 10000), test_model_accuracy(model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8431d-c3c3-429d-badd-a4eeaabfedc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087efba-fd72-4969-966d-01af1421a352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66647f36-1cf9-4db9-a2e7-d66942619db2",
   "metadata": {},
   "source": [
    "## 仅按输赢 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590adc1b-3e3e-41b1-8a0f-cffd136f35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(model, batch_size, n_test_rounds=0):\n",
    "    y_target_list = np.zeros((batch_size, 8))\n",
    "    state_list = np.array([make_state() for i in np.arange(batch_size)])\n",
    "    prob_list = model(np.array(state_list)).numpy()\n",
    "    actions = [np.random.choice(8, p=prob) for prob in prob_list]\n",
    "    optimal_actions = get_optimal_actions(state_list)\n",
    "    values = np.ones(batch_size)\n",
    "    values[actions != optimal_actions] = -1\n",
    "    values = (values - np.mean(values))/(np.std(values)+1e-6)\n",
    "    for i in np.arange(batch_size):\n",
    "        y_target_list[i, actions[i]] = values[i]\n",
    "    model.fit(state_list, np.array(y_target_list), verbose = 0)\n",
    "    if n_test_rounds > 0:\n",
    "        return (test_model_accuracy(model, n_test_rounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b5905-017f-4d7d-a823-54bc0533d8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21fb45e-e721-4217-baf3-a7dd4ec7a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_hidden_layers=1, n_dense_units=512, ratio_dropout=0.5, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b722f5a8-77dd-4775-97e2-5eb30139e3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1353\n",
      "1 0.1921\n",
      "2 0.2316\n",
      "3 0.2809\n",
      "4 0.3063\n",
      "5 0.3192\n",
      "6 0.3418\n",
      "7 0.3428\n",
      "8 0.3567\n",
      "9 0.3574\n",
      "10 0.3573\n",
      "11 0.3757\n",
      "12 0.3628\n",
      "13 0.3734\n",
      "14 0.3814\n",
      "15 0.4018\n",
      "16 0.3868\n",
      "17 0.3788\n",
      "18 0.3767\n",
      "19 0.3889\n",
      "20 0.3954\n",
      "21 0.424\n",
      "22 0.4351\n",
      "23 0.4504\n",
      "24 0.4657\n",
      "25 0.4874\n",
      "26 0.4955\n",
      "27 0.467\n",
      "28 0.5011\n",
      "29 0.5093\n",
      "30 0.5067\n",
      "31 0.5299\n",
      "32 0.535\n",
      "33 0.5275\n",
      "34 0.5013\n",
      "35 0.4828\n",
      "36 0.462\n",
      "37 0.459\n",
      "38 0.4925\n",
      "39 0.5076\n",
      "40 0.5277\n",
      "41 0.5282\n",
      "42 0.5311\n",
      "43 0.5194\n",
      "44 0.5135\n",
      "45 0.5055\n",
      "46 0.5304\n",
      "47 0.5368\n",
      "48 0.5213\n",
      "49 0.5235\n",
      "50 0.5264\n",
      "51 0.5238\n",
      "52 0.5194\n",
      "53 0.5389\n",
      "54 0.5258\n",
      "55 0.5344\n",
      "56 0.5434\n",
      "57 0.5316\n",
      "58 0.5539\n",
      "59 0.5611\n",
      "60 0.5685\n",
      "61 0.5665\n",
      "62 0.5711\n",
      "63 0.5787\n",
      "64 0.5737\n",
      "65 0.5645\n",
      "66 0.5373\n",
      "67 0.5195\n",
      "68 0.491\n",
      "69 0.5066\n",
      "70 0.5303\n",
      "71 0.5416\n",
      "72 0.5391\n",
      "73 0.5406\n",
      "74 0.5547\n",
      "75 0.5537\n",
      "76 0.5767\n",
      "77 0.5991\n",
      "78 0.6039\n",
      "79 0.6189\n",
      "80 0.6168\n",
      "81 0.6195\n",
      "82 0.6025\n",
      "83 0.5761\n",
      "84 0.6007\n",
      "85 0.6111\n",
      "86 0.6036\n",
      "87 0.5724\n",
      "88 0.5739\n",
      "89 0.6101\n",
      "90 0.5996\n",
      "91 0.5948\n",
      "92 0.6103\n",
      "93 0.633\n",
      "94 0.6458\n",
      "95 0.6559\n",
      "96 0.6471\n",
      "97 0.6628\n",
      "98 0.6683\n",
      "99 0.6651\n",
      "100 0.6526\n",
      "101 0.6453\n",
      "102 0.6423\n",
      "103 0.6423\n",
      "104 0.6563\n",
      "105 0.6669\n",
      "106 0.6614\n",
      "107 0.6671\n",
      "108 0.654\n",
      "109 0.649\n",
      "110 0.6545\n",
      "111 0.6549\n",
      "112 0.6532\n",
      "113 0.6448\n",
      "114 0.6445\n",
      "115 0.6303\n",
      "116 0.6134\n",
      "117 0.6122\n",
      "118 0.6245\n",
      "119 0.6286\n",
      "120 0.6391\n",
      "121 0.6519\n",
      "122 0.6528\n",
      "123 0.6079\n",
      "124 0.6189\n",
      "125 0.6551\n",
      "126 0.6393\n",
      "127 0.6266\n",
      "128 0.6291\n",
      "129 0.6511\n",
      "130 0.6484\n",
      "131 0.634\n",
      "132 0.6454\n",
      "133 0.6514\n",
      "134 0.6397\n",
      "135 0.6404\n",
      "136 0.6365\n",
      "137 0.6352\n",
      "138 0.6322\n",
      "139 0.63\n",
      "140 0.6372\n",
      "141 0.6267\n",
      "142 0.6213\n",
      "143 0.6294\n",
      "144 0.6221\n",
      "145 0.5919\n",
      "146 0.5772\n",
      "147 0.5687\n",
      "148 0.5763\n",
      "149 0.615\n",
      "150 0.6096\n",
      "151 0.5888\n",
      "152 0.5902\n",
      "153 0.6101\n",
      "154 0.5942\n",
      "155 0.5984\n",
      "156 0.6083\n",
      "157 0.6273\n",
      "158 0.6303\n",
      "159 0.6073\n",
      "160 0.5983\n",
      "161 0.6121\n",
      "162 0.5763\n",
      "163 0.5741\n",
      "164 0.5777\n",
      "165 0.5994\n",
      "166 0.6077\n",
      "167 0.6216\n",
      "168 0.6073\n",
      "169 0.6004\n",
      "170 0.615\n",
      "171 0.5982\n",
      "172 0.5926\n",
      "173 0.5743\n",
      "174 0.6032\n",
      "175 0.597\n",
      "176 0.5909\n",
      "177 0.6075\n",
      "178 0.5991\n",
      "179 0.5989\n",
      "180 0.5974\n",
      "181 0.5936\n",
      "182 0.5988\n",
      "183 0.5838\n",
      "184 0.5712\n",
      "185 0.5789\n",
      "186 0.5631\n",
      "187 0.5603\n",
      "188 0.5756\n",
      "189 0.5944\n",
      "190 0.5829\n",
      "191 0.5796\n",
      "192 0.5718\n",
      "193 0.5785\n",
      "194 0.5871\n",
      "195 0.5522\n",
      "196 0.5619\n",
      "197 0.5833\n",
      "198 0.5405\n",
      "199 0.5279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.int64(98), np.float64(0.8583872570381754), np.float64(0.6655))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx, best_score, best_weights = train(model, 200, verbose = 1)\n",
    "best_model = clone_model(model)\n",
    "best_model.set_weights(best_weights)\n",
    "best_idx, test_model(best_model, 10000), test_model_accuracy(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d184f2a-294c-41bb-b711-39a7abb42052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(98), np.float64(0.8613196933575142), np.float64(0.6643))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_idx, test_model(best_model, 10000), test_model_accuracy(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf95273-d9c8-4838-8b9b-87b616344021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7676207804029727), np.float64(0.5196))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, 10000), test_model_accuracy(model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396fb9a-a6e9-48c6-a135-0dae0ceb6c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909e68d-a202-4aa0-990a-996b1b1dec4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1251f6-7d40-4bc1-9030-d20ce6a70e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d9e25ca-d1e1-4df8-ab71-81bcf6bffe85",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "命中最优解为赢，否则为输。\n",
    "\n",
    "测试以下两种情况\n",
    "* 赢奖励1，输奖励-1\n",
    "* 赢奖励1，输奖励0\n",
    "\n",
    "加上归一化后，命中最优解的几率达到0.66，不过平均每局得分不见优势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58378c-ad7f-46e6-9d4a-9535f8c2f502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
