{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671eaf69-ce13-470a-b0e0-90c32a316449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from itertools import product\n",
    "\n",
    "def make_states(n):\n",
    "    states = np.zeros((n,8))\n",
    "    for i in np.arange(n):\n",
    "        idx = np.random.choice(8, size=3, replace=False)\n",
    "        states[i, idx] = np.random.uniform(0.0, 1.0, size=3)\n",
    "    return states\n",
    "    \n",
    "def run(state, action):\n",
    "    if state[action] != 0:\n",
    "        return state[action]\n",
    "    else:\n",
    "        before, after = state[(action - 1) % 8], state[(action + 1) % 8]\n",
    "        if before != 0 and after != 0:\n",
    "            return before + after\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def get_optimal_action_and_value(state):\n",
    "    values = np.array([run(state, action) for action in np.arange(8)])\n",
    "    optimal_action = values.argmax()\n",
    "    return optimal_action, values[optimal_action]\n",
    "\n",
    "def get_optimal_actions_and_values(state_list):\n",
    "    res = [get_optimal_action_and_value(state) for state in state_list]\n",
    "    actions = np.array([pairs[0] for pairs in res])\n",
    "    values = np.array([pairs[1] for pairs in res])\n",
    "    return actions, values\n",
    "    \n",
    "def get_optimal_statics(n_rounds):\n",
    "    state_list = make_states(n_rounds)\n",
    "    _, values = get_optimal_actions_and_values(state_list)\n",
    "    return np.mean(values), np.std(values)\n",
    "\n",
    "def get_random_policy_statics(n_rounds):\n",
    "    values = [run(state, np.random.choice(8)) for state in make_states(n_rounds)]\n",
    "    return np.mean(values), np.std(values)\n",
    "\n",
    "def get_model_actions(model, state_list):\n",
    "    return model(np.array(state_list)).numpy().argmax(axis = 1)\n",
    "\n",
    "def test_model(model, n_test_rounds):\n",
    "    state_list = make_states(n_test_rounds)\n",
    "    actions = get_model_actions(model, state_list)\n",
    "    values = [run(state, action) for state, action in zip(state_list, actions)]\n",
    "    optimal_actions, _ = get_optimal_actions_and_values(state_list)\n",
    "    accuracy = np.mean(actions == optimal_actions)\n",
    "    return np.mean(values), np.std(values), accuracy\n",
    "\n",
    "def one_batch(model, optimizer, batch_size=128, n_test_rounds=10000):\n",
    "    states = make_states(batch_size)\n",
    "    _, optimal_values = get_optimal_actions_and_values(states)\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs = model(states)\n",
    "\n",
    "        actions = np.array([np.random.choice(8, p=prob) for prob in probs.numpy()])\n",
    "        rewards = np.array([run(state, action) for state, action in zip(states, actions)])\n",
    "        rewards = rewards - optimal_values\n",
    "        rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-8)\n",
    "\n",
    "        action_probs = tf.gather_nd(probs, [[i, a] for i, a in enumerate(actions)])\n",
    "        log_probs = tf.math.log(action_probs)\n",
    "        loss = -tf.reduce_mean(log_probs * rewards)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "def train(model, optimizer, one_batch, max_batch=200, batch_size=32, test_lapse = 10, n_test_rounds=10000, verbose = 0):\n",
    "    best_weights = []\n",
    "    best_idx = 0\n",
    "    best_score = 0\n",
    "    for i in np.arange(max_batch):\n",
    "        one_batch(model, optimizer, batch_size)\n",
    "        if (i+1) % test_lapse == 0 or i + 1 == max_batch:\n",
    "            score, _, accuracy = test_model(model, n_test_rounds)\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                best_idx = i\n",
    "                best_weights = model.get_weights()\n",
    "            if verbose == 1:\n",
    "                print(i+1, score, accuracy)\n",
    "    return best_idx, best_score, best_weights\n",
    "\n",
    "def create_model(n_hidden_layers, n_dense_units, ratio_dropout):\n",
    "    input_shape = (8,) \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for i in np.arange(n_hidden_layers):\n",
    "        x = Dense(n_dense_units)(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Dropout(ratio_dropout)(x)\n",
    "    \n",
    "    outputs = Dense(8, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2f8a7-3b24-4cb8-b9d6-61b763006e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68c74e-9ec2-41fb-9461-d5a9b3bd2875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8b5fc2-fa92-45bd-a974-147de72e1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_hidden_layers=2, n_dense_units=256, ratio_dropout=0.2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508880be-f86f-47e3-bb43-1a9a00398346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.7339654840427151 0.4197\n",
      "40 0.7318226986132617 0.4122\n",
      "60 0.7334543882296721 0.4015\n",
      "80 0.7397083137278935 0.4244\n",
      "100 0.7631010915801264 0.4549\n",
      "120 0.7760599521337408 0.4729\n",
      "140 0.7788991718142902 0.4997\n",
      "160 0.7851579011504027 0.5178\n",
      "180 0.7943545117174379 0.5216\n",
      "200 0.7979974383209517 0.5188\n",
      "220 0.8090956493070987 0.5481\n",
      "240 0.8157016234142183 0.5532\n",
      "260 0.8245638989394385 0.5661\n",
      "280 0.8305260406706828 0.5805\n",
      "300 0.8328790437151999 0.5956\n",
      "320 0.8318754286374253 0.5906\n",
      "340 0.8353415596053414 0.5839\n",
      "360 0.835951840604878 0.6094\n",
      "380 0.8483075019872139 0.6142\n",
      "400 0.8500449676547116 0.6338\n",
      "420 0.8361121828732999 0.6034\n",
      "440 0.8477111224868346 0.6217\n",
      "460 0.8568629147846292 0.656\n",
      "480 0.861327568371441 0.645\n",
      "500 0.8613537610016272 0.6523\n",
      "520 0.8634251765085188 0.657\n",
      "540 0.8647760004490452 0.6642\n",
      "560 0.872109582741807 0.6708\n",
      "580 0.8664021290651801 0.672\n",
      "600 0.8669640810531977 0.6798\n",
      "620 0.874615604978736 0.6841\n",
      "640 0.8651986231690231 0.688\n",
      "660 0.8759120958599056 0.7067\n",
      "680 0.8741307525899726 0.7003\n",
      "700 0.8760669749206068 0.6947\n",
      "720 0.877374407485492 0.7066\n",
      "740 0.8732655894048498 0.7031\n",
      "760 0.8759042226763686 0.7072\n",
      "780 0.8741125043434517 0.7116\n",
      "800 0.8759314368983608 0.7147\n",
      "820 0.8783127066697454 0.7264\n",
      "840 0.8840676186428896 0.7251\n",
      "860 0.8794934721680085 0.7401\n",
      "880 0.881780914175623 0.7152\n",
      "900 0.8833256338371531 0.744\n",
      "920 0.8848391773782845 0.7416\n",
      "940 0.8885272166384791 0.7344\n",
      "960 0.8871777786333791 0.7399\n",
      "980 0.8847129284817925 0.7413\n",
      "1000 0.8906165649499722 0.746\n"
     ]
    }
   ],
   "source": [
    "best_idx, best_score, best_weights = train(model, optimizer, one_batch, max_batch=1000, batch_size=128, test_lapse = 20, n_test_rounds=10000, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c2c2b1c-ba81-485e-b504-f6467a10e0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8831582976087564),\n",
       " np.float64(0.37827467223514566),\n",
       " np.float64(0.7421))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235c524e-a046-4b62-9343-affdb0ee07c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8885815101340466),\n",
       " np.float64(0.3783373587545388),\n",
       " np.float64(0.7435))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = clone_model(model)\n",
    "best_model.set_weights(best_weights)\n",
    "test_model(best_model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba32db1-886b-4264-b385-978ce2a34659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
