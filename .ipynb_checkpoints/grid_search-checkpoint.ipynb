{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424fc8e6-e309-4608-b270-a4fd7161eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from itertools import product\n",
    "\n",
    "import functions as fs\n",
    "from functions import make_state, run, get_optimal_value, get_optimal_action, get_optimal_actions, get_model_actions, test_model, one_batch, test_model_accuracy, one_batch_supervised, train, train_supervised, create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5d4ac-5549-4dc6-b7cc-97e21e379fcb",
   "metadata": {},
   "source": [
    "# 单步奖励收集\n",
    "\n",
    "这是一个用于练习策略梯度法 (policy gradient method) 的玩具题。  \n",
    "8个格子首尾相连，其中随机3个格子奖励，奖励数值为0~1的均匀随机数。  \n",
    "动作：选择一个格子。\n",
    "计分规则：  \n",
    "1. 如果格子有奖励（大于0），获得对应的奖励。\n",
    "2. 如果格子是空的（等于0），且两侧的格子都有奖励，会获得两侧格子的总奖励。\n",
    "3. 否则奖励为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ccc071-42da-41b2-b9ca-44d190836c03",
   "metadata": {},
   "source": [
    "## 测试hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fe806e-7834-46b4-bda2-d3e32d92bda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd 1 64 0.2 204 0.8248358598306655\n",
      "sgd 1 64 0.3 159 0.8305548017766521\n",
      "sgd 1 64 0.4 231 0.8280183309475164\n",
      "sgd 1 64 0.5 292 0.8177246414354393\n",
      "sgd 1 64 0.6 217 0.8160378401679262\n",
      "sgd 1 64 0.7 207 0.8307612579383953\n",
      "sgd 1 128 0.2 181 0.8500731975526788\n",
      "sgd 1 128 0.3 196 0.8590271956423483\n",
      "sgd 1 128 0.4 164 0.8403888276563491\n",
      "sgd 1 128 0.5 197 0.8415861312996321\n",
      "sgd 1 128 0.6 175 0.849156561100324\n",
      "sgd 1 128 0.7 241 0.8570490655679734\n",
      "sgd 1 256 0.2 137 0.8767178277734814\n",
      "sgd 1 256 0.3 163 0.8751898127784395\n",
      "sgd 1 256 0.4 196 0.8929618962541235\n",
      "sgd 1 256 0.5 183 0.8678954191929861\n",
      "sgd 1 256 0.6 155 0.8776852263183684\n",
      "sgd 1 256 0.7 190 0.855041421452595\n",
      "sgd 1 512 0.2 177 0.9002695710875036\n",
      "sgd 1 512 0.3 143 0.8980001387826704\n",
      "sgd 1 512 0.4 168 0.8888414414734253\n",
      "sgd 1 512 0.5 169 0.8973560204168048\n",
      "sgd 1 512 0.6 173 0.8997983320175176\n",
      "sgd 1 512 0.7 214 0.878271239572213\n",
      "sgd 2 64 0.2 290 0.8030141960436504\n",
      "sgd 2 64 0.3 201 0.8129056165957603\n",
      "sgd 2 64 0.4 178 0.8031456692799241\n",
      "sgd 2 64 0.5 188 0.7912667321951157\n",
      "sgd 2 64 0.6 269 0.7862623125696767\n",
      "sgd 2 64 0.7 280 0.7644235476174089\n",
      "sgd 2 128 0.2 169 0.8347220963532611\n",
      "sgd 2 128 0.3 196 0.8469772818008633\n",
      "sgd 2 128 0.4 183 0.8329781606906972\n",
      "sgd 2 128 0.5 245 0.8254641645609009\n",
      "sgd 2 128 0.6 219 0.8182568744521966\n",
      "sgd 2 128 0.7 183 0.8215087482847383\n",
      "sgd 2 256 0.2 239 0.7918391211328903\n",
      "sgd 2 256 0.3 141 0.8046617709306964\n",
      "sgd 2 256 0.4 146 0.8387938397664868\n",
      "sgd 2 256 0.5 161 0.8276279515611219\n",
      "sgd 2 256 0.6 128 0.8520309066541822\n",
      "sgd 2 256 0.7 164 0.8257065112468835\n",
      "sgd 2 512 0.2 154 0.7876696014282571\n",
      "sgd 2 512 0.3 169 0.8140159287825616\n",
      "sgd 2 512 0.4 174 0.7987961438163357\n",
      "sgd 2 512 0.5 162 0.8239893201718849\n",
      "sgd 2 512 0.6 149 0.8338660342598491\n",
      "sgd 2 512 0.7 121 0.8259515360280096\n",
      "adam 1 64 0.2 146 0.8300513500606354\n",
      "adam 1 64 0.3 145 0.8409440386771349\n",
      "adam 1 64 0.4 133 0.8343533852175166\n",
      "adam 1 64 0.5 197 0.8555179675291825\n",
      "adam 1 64 0.6 164 0.8396569842795805\n",
      "adam 1 64 0.7 168 0.8588341219982673\n",
      "adam 1 128 0.2 100 0.8584715363798361\n",
      "adam 1 128 0.3 153 0.8594449445411468\n",
      "adam 1 128 0.4 132 0.8470844137394367\n",
      "adam 1 128 0.5 116 0.8633797033176265\n",
      "adam 1 128 0.6 111 0.8730953337754663\n",
      "adam 1 128 0.7 166 0.8678937726169017\n",
      "adam 1 256 0.2 88 0.8699501976644289\n",
      "adam 1 256 0.3 116 0.859231374652978\n",
      "adam 1 256 0.4 95 0.8887198387688481\n",
      "adam 1 256 0.5 107 0.8890870939907886\n",
      "adam 1 256 0.6 132 0.883180564811074\n",
      "adam 1 256 0.7 114 0.8766374713356476\n",
      "adam 1 512 0.2 56 0.8978368808929011\n",
      "adam 1 512 0.3 75 0.8715465212587152\n",
      "adam 1 512 0.4 88 0.8788015865440256\n",
      "adam 1 512 0.5 99 0.8845044566595368\n",
      "adam 1 512 0.6 83 0.8937330374609934\n",
      "adam 1 512 0.7 135 0.8939753393763933\n",
      "adam 2 64 0.2 124 0.7834124160851136\n",
      "adam 2 64 0.3 89 0.7701607908593394\n",
      "adam 2 64 0.4 131 0.7700254006381893\n",
      "adam 2 64 0.5 134 0.8196496754937062\n",
      "adam 2 64 0.6 141 0.7770407629292639\n",
      "adam 2 64 0.7 142 0.7490819704419763\n",
      "adam 2 128 0.2 177 0.7925064658336216\n",
      "adam 2 128 0.3 280 0.7270392347541542\n",
      "adam 2 128 0.4 148 0.7891487754182902\n",
      "adam 2 128 0.5 86 0.784537569467463\n",
      "adam 2 128 0.6 107 0.7672344182446759\n",
      "adam 2 128 0.7 119 0.7788409406812369\n",
      "adam 2 256 0.2 208 0.7491783115528905\n",
      "adam 2 256 0.3 285 0.7603902621000742\n",
      "adam 2 256 0.4 146 0.7650949689275535\n",
      "adam 2 256 0.5 208 0.7606062818206044\n",
      "adam 2 256 0.6 93 0.7192400397107167\n",
      "adam 2 256 0.7 96 0.7899569102971217\n",
      "adam 2 512 0.2 250 0.7684738426676581\n",
      "adam 2 512 0.3 227 0.7651638074622907\n",
      "adam 2 512 0.4 236 0.7701740406325329\n",
      "adam 2 512 0.5 239 0.7646603472995123\n",
      "adam 2 512 0.6 274 0.7446774108705029\n",
      "adam 2 512 0.7 117 0.7817009134975271\n"
     ]
    }
   ],
   "source": [
    "for optimilizer in ['sgd', 'adam']:\n",
    "    for n_hidden_layers in [1, 2]:\n",
    "        for n_dense_units in [64, 128, 256, 512]:\n",
    "            for ratio_dropout in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "                model = create_model(n_hidden_layers, n_dense_units, ratio_dropout, optimilizer)\n",
    "                scores = np.array([one_batch(model, batch_size=128, n_test_rounds=10000) for i in np.arange(300)])\n",
    "                argmax = scores.argmax()\n",
    "                print(optimilizer, n_hidden_layers, n_dense_units, ratio_dropout, argmax, scores[argmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5d847-e9cd-4925-9953-ad01135a2a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e3fe0-c5f1-4880-86e8-d4db3093a4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
