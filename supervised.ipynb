{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424fc8e6-e309-4608-b270-a4fd7161eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from itertools import product\n",
    "\n",
    "import functions as fs\n",
    "from functions import make_state, run, get_optimal_value, get_optimal_action, get_optimal_actions, get_model_actions, test_model, one_batch, test_model_accuracy, one_batch_supervised, train, train_supervised, create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5d4ac-5549-4dc6-b7cc-97e21e379fcb",
   "metadata": {},
   "source": [
    "# 单步奖励收集\n",
    "\n",
    "这是一个用于练习策略梯度法 (policy gradient method) 的玩具题。  \n",
    "8个格子首尾相连，其中随机3个格子奖励，奖励数值为0~1的均匀随机数。  \n",
    "动作：选择一个格子。\n",
    "计分规则：  \n",
    "1. 如果格子有奖励（大于0），获得对应的奖励。\n",
    "2. 如果格子是空的（等于0），且两侧的格子都有奖励，会获得两侧格子的总奖励。\n",
    "3. 否则奖励为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc104180-5426-44ec-a82b-4d864b068367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c2bd7ed-441c-4dc9-ae7a-5ce0a491f53f",
   "metadata": {},
   "source": [
    "## 测试监督学习效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc9ea7-92b3-405b-b314-b70375d494be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd 1 64 0.2 290 0.8894605271764167\n"
     ]
    }
   ],
   "source": [
    "for optimilizer in ['sgd', 'adam']:\n",
    "    for n_hidden_layers in [1, 2]:\n",
    "        for n_dense_units in [64, 128, 256, 512]:\n",
    "            for ratio_dropout in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "                model_supervised = create_model(n_hidden_layers, n_dense_units, ratio_dropout, optimilizer)\n",
    "                scores = np.array([one_batch_supervised(model_supervised, batch_size=128, n_test_rounds=10000) for i in np.arange(300)])\n",
    "                argmax = scores.argmax()\n",
    "                print(optimilizer, n_hidden_layers, n_dense_units, ratio_dropout, argmax, scores[argmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e3fe0-c5f1-4880-86e8-d4db3093a4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
